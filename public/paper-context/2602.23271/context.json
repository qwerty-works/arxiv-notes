{
  "arxivId": "2602.23271",
  "paperTitle": "Evaluating Stochasticity in Deep Research Agents",
  "abstract": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.",
  "chunks": [
    {
      "id": "abs-0",
      "type": "abstract",
      "text": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality."
    },
    {
      "id": "cap-0",
      "type": "caption",
      "text": "Figure 1: Overview of the evaluation pipeline. The process begins with a user question which triggers multiple"
    },
    {
      "id": "cap-1",
      "type": "caption",
      "text": "Table 1: Full Ablation Results. A comprehensive breakdown of stochasticity metrics across varying temperatures"
    },
    {
      "id": "cap-2",
      "type": "caption",
      "text": "Figure 2: Comprehensive Analysis of Stochasticity Behavior. (a) Early-stage injections dominate propagation. (b)"
    },
    {
      "id": "cap-3",
      "type": "caption",
      "text": "Table 2: Examples showing that higher stochasticity does not monotonically improve accuracy. We select examples that"
    },
    {
      "id": "cap-4",
      "type": "caption",
      "text": "Table 3: Average stochasticity of findings vs. citations across modules, steps, and temperatures."
    },
    {
      "id": "cap-5",
      "type": "caption",
      "text": "Table 4: Comparison of Stochasticity Mitigation Strategies. The best performance in each category is highlighted"
    },
    {
      "id": "cap-6",
      "type": "caption",
      "text": "Table 5: Stochasticity and Accuracy Metrics across Sampling Temperatures (λ) under API Setting."
    },
    {
      "id": "b-0",
      "type": "body",
      "text": "E VALUATING S TOCHASTICITY IN D EEP R ESEARCH AGENTS\n\nHaotian Zhai1 , Elias Stengel-Eskin1 , Pratik Patil1 , Liu Leqi1\n                                                                                        1\n                                                                                            University of Texas at Austin∗\n\nA BSTRACT\narXiv:2602.23271v1 [cs.AI] 26 Feb 2026"
    },
    {
      "id": "b-1",
      "type": "body",
      "text": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information\n                                                     to support research across domains such as financial decision-making, medical analysis, and scientific\n                                                     discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground\n                                                     truth is available), DRA system design often overlooks a critical barrier to real-world deployment:\n                                                     stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability\n                                                     in terms of research outcome, findings, and citations. In this paper, we formalize the study of\n                                        "
    },
    {
      "id": "b-2",
      "type": "body",
      "text": "1       Introduction"
    },
    {
      "id": "b-3",
      "type": "body",
      "text": "Deep Research Agents (DRAs) are a specialized class of LLM-driven agents designed for autonomous knowledge\n                                         discovery [10]. By interleaving iterative tool execution with adaptive reasoning and planning [25, 19], these agents\n                                         systematically retrieve and synthesize external data to fulfill complex, information-heavy research objectives [3, 8, 21].\n                                         However, the deployment of DRAs is hindered by a fundamental lack of reliability. The execution of a DRA involves an\n                                         iterative cycle of search, reasoning, and synthesis, where minor generation or search variations can cascade into vastly\n                                         different research conclusions. This stochasticity, manifesting as significant variability in research output,"
    },
    {
      "id": "b-4",
      "type": "body",
      "text": "task-relevant atomic findings and citations to source documents. This formulation provides a unifying abstraction for\nanalyzing DRA’s behavior across heterogeneous tasks and instantiations.\nBuilding on this formulation, we introduce a suite of metrics that characterize DRA stochasticity at multiple levels,\nincluding variability in final research outputs (e.g., answers), findings, and citation sources. These metrics enable\nfine-grained measurements that allow us to disentangle whether two runs disagree because they retrieve and cite different\nevidence, reason differently over the same evidence, or both.\nWe then adopt a measurement framework grounded in variance decomposition that attributes stochasticity in DRA’s\nevolving knowledge state to two sources: (i) propagated stochasticity inherited from earlier states, and (ii) intrinsic\nstochasticity arising from the current decision modules. T"
    },
    {
      "id": "b-5",
      "type": "body",
      "text": "• We identify the stochasticity problem and propose an information acquisition MDP formulation for deep research\n      agents that supports principled analysis of stochasticity (Section 3).\n    • We introduce multi-level stochasticity metrics over answers, findings, and citations for evaluating stochasticity\n      across executions (Section 4).\n    • We conceptually decompose DRA stochasticity into propagated and intrinsic stochasticity across agent modules\n      (Section 5.1), and introduce temperature ablation experiments to empirically investigate how these naturally\n      entangled sources of uncertainty propagate and affect the final output stochasticity (Section 5.2).\n    • We propose mitigation strategies that substantially reduce stochasticity without degrading answer accuracy\n      (Section 6).\n\n2    Related Work"
    },
    {
      "id": "b-6",
      "type": "body",
      "text": "Deep research and browsing agents. The evolution of Deep Research Agents (DRAs) stems from early Retrieval-\nAugmented Generation (RAG) systems, which utilized large corpora to enhance factual accuracy in knowledge-intensive\nquestion answering [12, 5]. While initial efforts focused on short-form factoid synthesis [11, 18, 27, 13], these methods\noften lack the reasoning depth required for comprehensive reports [6, 17]. Frameworks such as GPTResearcher\n[4] have bridged this gap by integrating agentic workflows for long-form generation, utilizing query decomposition\nand hierarchical planning to ensure completeness. Contemporary systems such as OpenDeepSearch [1] and Tongyi\nDeepResearch [19] further extend these capabilities by interleaving iterative action-observation cycles with external tool\nuse, such as Python execution. Other work such as FlashResearch [16] also focuses on real-time agen"
    },
    {
      "id": "b-7",
      "type": "body",
      "text": "2\n\fEvaluating Stochasticity in Deep Research Agents\n\nframework to evaluate the stochasticity, attributing stochasticity to different components, and proposing stochasticity\nmitigation methods in DRAs."
    },
    {
      "id": "b-8",
      "type": "body",
      "text": "3    Modeling Deep Research Agents\nWe model a single execution run of a deep research agent as an information acquisition MDP. Let Q denote the set of\nall problem instances (user queries). For a fixed instance q ∈ Q, let F(q) = {f1 , . . . , fN } denote a finite universe of\ncandidate atomic findings relevant to q.\nAt step t, we track an abstract knowledge state bt ∈ {0, 1}N , where bt [k] = 1 indicates that finding fk is supported by\nthe evidence acquired so far. We initialize b0 = 0. At each step, the agent either issues an information-seeking query or\nterminates. Let the action space be A = S ∪ {STOP}, where S is the set of allowable search queries. The agent samples\nan action\n                                                 at ∼ πquery (· | q, bt ),                                            (1)\nwhere πquery is the query policy. If at = STOP the run terminates. Otherwise, the environm"
    },
    {
      "id": "b-9",
      "type": "body",
      "text": "4    Evaluation Framework for DRA Stochasticity\nWe quantify stochasticity by running the same agent n times on the same instance q under identical configuation,\nproducing trajectories T = {τ (1) , . . . , τ (n) } and final reports {r(1) , . . . , r(n) }. For each report, we extract three objects\nof interest: (i) an answer (when a verifiable answer exists), (ii) a set of atomic findings, and (iii) a set of citations\n(URLs). We then cannonicalize these objects across runs and map each run to a vector representation that enables a\nunified variance-based metric.\nWe have three random vectors of interest: the answer Y, the citations C, and the findings B. They are all categorical\ndistributions and can be represented in similar ways. Note that for open-ended questions, we lack answers Y. Thus, in\nthe following, we model the agent’s output as a realization of a random vector X ∈ {0, 1}d . While "
    },
    {
      "id": "b-10",
      "type": "body",
      "text": "3\n\fEvaluating Stochasticity in Deep Research Agents\n\nDRAs                        Decomposition                     Vectorization\n                                                                 & Clustering                      & Metrics\n                                          Answer ..."
    },
    {
      "id": "b-11",
      "type": "body",
      "text": "Input                            Findings                       Answers ...\n                                             A\n      According to\n      Director's Annual                                                                              Normalization\n                                             B\n      Reports, which year\n                            Run 1\n      saw the largest                                                      Findings\n      percent change\n                                         Citations ...\n                                                                          A        A\n      decrease                           Report 1\n      in the number\n      of secondary                        Answer ...                          B\n      school students?\n                                          Findings                                                Metrics Calculation\n"
    },
    {
      "id": "b-12",
      "type": "body",
      "text": "Figure 1: Overview of the evaluation pipeline. The process begins with a user question which triggers multiple\nindependent Deep Research Agent (DRA) runs (in this example we use number of runs k = 2). The resulting reports\nare decomposed into answers, findings, and citations, and then clustered. After clustering, each report’s answers,\nfindings, and citations are mapped to binary vectors and normalized to compute the Total Variance (TV) as a measure of\nstochasticity. We expand findings as an example to illustrate the whole process. In reality, answers and citations are also\nprocessed in similar ways as in Section 4."
    },
    {
      "id": "b-13",
      "type": "body",
      "text": "1. Answers (Y): The answer per run is a categorical random variable modeled as a one-hot vector y ∈ {0, 1}KA . Here,\n   KA represents the total number of unique answers observed across all runs. The support of Y is the set of standard\n   basis vectors {e1 , . . . , eKA }. Note that answers exist only for questions that are not open-ended. For open-ended\n   questions, this can be replaced by some measurement on the quality of report.\n2. Findings (B): The findings per run are modeled as a binary vector b ∈ {0, 1}KF . Here, KF is the size of the global\n   union of unique findings across runs. The global set of findings is indexed from 1 to KF , such that a value of 1 at\n   the k-th entry of b indicates the presence of the k-th finding in that run.\n3. Citations (C): The citations per run are modeled as a binary vector c ∈ {0, 1}KC . Here, KC is the size of the\n   global union of unique citat"
    },
    {
      "id": "b-14",
      "type": "body",
      "text": "4.1    Total Variance as a Measure of Stochasticity"
    },
    {
      "id": "b-15",
      "type": "body",
      "text": "We seek a scalar that captures run-to-run variability. We use the trace of the covariance (“total variance”) of the\nembedded output vector. Let us recall a convenient identity.\nProposition 4.1. Let X be a random vector in Rd with finite mean µ = E[X] and covariance matrix Σ = Var(X).\nLet X1 and X2 be independent and identically distributed (i.i.d.) copies of X. The covariance matrix Σ is given by:\n                                             1 \u0002\n                                        Σ = E (X1 − X2 )(X1 − X2 )⊤ .\n                                                                            \u0003\n                                             2\nCorollary 4.2 (Total variance). We have\n                                                            1 \u0002\n                                     TV(X) := Tr(Σ) = E ∥X1 − X2 ∥2 .\n                                                                              \u0003\n "
    },
    {
      "id": "b-16",
      "type": "body",
      "text": "4\n\fEvaluating Stochasticity in Deep Research Agents\n\nx(i) }ni=1 , we estimate:\nGiven n runs with normalized vectors {e\n\nn X n\n                                                       1     X\n                                       TV(\n                                       d X)e =                       ∥e    e j ∥2 .\n                                                                      xi − x                                             (6)\n                                                   2n(n − 1) i=1 j=1"
    },
    {
      "id": "b-17",
      "type": "body",
      "text": "This is a U-statistic estimator corresponding to (5) which is unbiased. Before applying the estimator TV\n                                                                                                      d to our variables\nof interest, we must ensure that the vector dimensions are semantically consistent across the n independent runs, i.e.,\ndimension 3 for different x ei should represent the same answer/finding/citation.\nFor one-hot answers, TV(\n                      d X) e equals the empirical probability that two independent runs yield different canonical\nanswers. For binary findings/citations, normalization yields a cosine-overlap notion: the metric increases when runs\nshare fewer canonical items relative to their sizes. We provide further interpretation and analysis of TV\n                                                                                                       d in Ap"
    },
    {
      "id": "b-18",
      "type": "body",
      "text": "4.2   Constructing Metrics from Agent Outputs"
    },
    {
      "id": "b-19",
      "type": "body",
      "text": "To implement the proposed variance estimators on real agent outputs, we need to extract the required information from\nthe agent’s final report. We take the agent’s final report, and adopt a decomposition procedure inspired by FactScore [14].\nWe extract: (i) the final answer (for non–open-ended tasks), (ii) all URLs as citations, and (iii) a set of atomic findings\nobtained by decomposing the final report into minimal factual claims using LLM for each report. We include our\nprompts in Appendix B.\nTo ensure cross-run semantic alignment, findings from all trajectories are clustered into canonical findings using\nLLM-as-a-judge that determines whether two findings express the same underlying fact. Citations are canonicalized via\nURL normalization followed by exact string matching. After that, analogous binary vectors are constructed for answers\nand citations using their respective canonical se"
    },
    {
      "id": "b-20",
      "type": "body",
      "text": "5     Analysis of Stochasticity via Variance Decomposition\nFollowing the metrics and evaluation pipeline we proposed in Section 4, we model the progression of the random\nvariable of interest over time, denoted as Xt (e.g., the accumulated findings or citations at step t). Since TV corresponds\nto the trace of the covariance matrix, it allows us to apply the Law of Total Variance to mathematically decompose the\nvariance of Xt+1 , identifying how a policy (πquery , πsum , πupdate ) introduce stochasticity at each step.\n\n5.1   Decomposing Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-21",
      "type": "body",
      "text": "As DRAs iteratively gather and process information, stochasticity accumulates at each decision step. While we model\nthis process as an information acquisition MDP, isolating the exact contribution of every variable during a full execution\nis computationally intractable. However, to understand and mitigate the variance in the final research output, we\nconceptually decompose the stochasticity at any given step t into two primary components:\nPropagated Stochasticity. This represents the stochasticity inherited from previous steps. Because a DRA’s current\naction depends on its prior state (e.g., previous search results and intermediate reasoning), any stochasticity introduced\nearly in the process naturally cascades. Conceptually, it captures how much of the stochasticity in the next state\nXt+1 is simply a result of the agent starting from a noisy or varying distribution at Xt . Even if the a"
    },
    {
      "id": "b-22",
      "type": "body",
      "text": "5\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-23",
      "type": "body",
      "text": "To provide a structural lens for auditing this uncertainty, we further categorize Intrinsic Stochasticity based on the three\ndistinct functional modules of the DRA at each step:\n • Information Acquisition (∆Query ): The stochasticity introduced when the agent formulates search queries. Different\n   phrasings of search queries can lead to vastly different retrieved documents and paragraphs.\n • Information Compression (∆Sum ): The stochasticity introduced when the agent parses, filters, and summarizes the\n   raw retrieved content. Different extractions of facts from the exact same source document lead to divergent contexts.\n • Inference (∆Update ): The stochasticity introduced when the agent reasons over the newly synthesized information to\n   update its internal belief state, answer open questions, or draw intermediate conclusions.\nWe provide the mathematical formulation of the stochastic"
    },
    {
      "id": "b-24",
      "type": "body",
      "text": "Table 1: Full Ablation Results. A comprehensive breakdown of stochasticity metrics across varying temperatures\n(λ), temporal injection points (Steps), and specific modules. This table corresponds to the experimental decomposition\nanalyzed in Section 5.1.\n                                                                          q\n                                                      c X)\n                                                      TV( e                TV(∥X∥\n                                                                            c    0)          Mean Count (µ)\n      λ        Step        Module                                                                                Acc.\n                                               Ans.     Find.      Cit.   Find.     Cit.      Find.     Cit."
    },
    {
      "id": "b-25",
      "type": "body",
      "text": "Query (πquery )     0.37     0.76       0.42   29.97     2.10      90.82     6.62     0.40\n                 1         Sum (πsum )         0.58     0.84       0.52   32.01     2.17      90.84     6.46     0.40\n                           Update (πupdate )   0.59     0.85       0.55   31.45     2.49      88.80     6.96     0.52"
    },
    {
      "id": "b-26",
      "type": "body",
      "text": "Query               0.36     0.70       0.30   27.35     2.30      92.46     5.96     0.46\n                 2         Sum                 0.36     0.65       0.38   30.85     2.60      88.14     6.48     0.44\n      0.5                  Update              0.38     0.82       0.40   28.68     2.48      96.58     6.40     0.40\n                           Query               0.36     0.61       0.30   32.08     2.26      86.92     6.08     0.34\n                 3         Sum                 0.28     0.52       0.28   31.88     2.14      96.82     6.84     0.34\n                           Update              0.32     0.68       0.34   32.62     2.67      89.96     6.32     0.44\n                           Query               0.44     0.76       0.50   35.84     2.41     102.90     6.52     0.40\n             Combined      Sum                 0.59     0.84       0.55   34.46     2.76     89.52   "
    },
    {
      "id": "b-27",
      "type": "body",
      "text": "Query (πquery )     0.51     0.80       0.46   25.98     2.71      91.38     6.12     0.36\n                 1         Sum (πsum )         0.53     0.88       0.51   38.32     2.51      88.46     6.60     0.46\n                           Update (πupdate )   0.62     0.89       0.59   28.22     2.48      88.10     6.70     0.46"
    },
    {
      "id": "b-28",
      "type": "body",
      "text": "Query               0.43     0.79       0.45   25.85     1.93      93.53     6.74     0.42\n                 2         Sum                 0.37     0.54       0.29   24.57     1.63      93.77     6.02     0.46\n      1.0                  Update              0.40     0.85       0.48   28.48     2.14      84.60     6.62     0.40\n                           Query               0.34     0.63       0.32   30.65     1.90     83.54      6.30     0.50\n                 3         Sum                 0.30     0.53       0.29   31.29     2.04     94.47      6.09     0.38\n                           Update              0.41     0.63       0.38   37.55     2.68     101.00     6.70     0.40\n                           Query               0.49     0.87       0.51   36.14     2.70      89.50     6.52     0.50\n             Combined      Sum                 0.61     0.92       0.62   34.93     2.67      88.93  "
    },
    {
      "id": "b-29",
      "type": "body",
      "text": "6\n\fEvaluating Stochasticity in Deep Research Agents\n\n5.2   Empirical Investigation via Temperature Ablation"
    },
    {
      "id": "b-30",
      "type": "body",
      "text": "To empirically quantify these theoretical components, we leverage temperature to control the variance of different\npolicies. By increasing the temperature λ for specific policy modules (πquery , πsum , πupdate ) at specific steps while setting\nλ = 0 (greedy decoding) for others, we empirically investigate how these modules affect DRA’s stochasticity over time.\nWe applied these temperature controls at distinct temporal stages: early (Step 1), middle (Step 2), late (Step 3), and\ncombined (Steps 1–3). This setup allows us to trace how stochasticity introduced by specific modules at specific times\nimpacts the variance of the final research output XT .\nFor the DRA system, we use ReAct realization based on Tongyi DeepResearch [19]. In order to see the relationship\nbetween accuracy and stochasticity, we use 20 instances from QA dataset WebWalkerQA [22]. We use Qwen3-30B-\nA3B-Instruct-2507 [24] "
    },
    {
      "id": "b-31",
      "type": "body",
      "text": "(a) Propagation of stochasticity across steps.\n\n(c) Effect of temperature on total variance.\n\n(b) Pairwise correlations of stochasticity metrics.                     (d) Module-wise contribution to stochasticity.\n\nFigure 2: Comprehensive Analysis of Stochasticity Behavior. (a) Early-stage injections dominate propagation. (b)\nStrong positive correlations across answer, finding, and citation TV. (c) Higher sampling temperature increases total\nvariance. (d) The Update module contributes the largest variance.\n\n7\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-32",
      "type": "body",
      "text": "Finding 1: Early-stage stochasticity influences final-stage stochasticity more than late-stage stochasticity. To\nisolate temporal stochasticity effects independent of module choices, we average TV(        d X)  e over the three modules\n(πquery , πsum , πupdate ) for each perturbation step. Figure 2a plot the resulting mean final variance for answer-level (Y),\nfinding-level (B), and citation-level (C) variances.\nAcross both temperatures and variance types, applying higher stochasticity to different modules at earlier steps\nconsistently yields greater final variance than applying the same stochasticity at later stages. This empirical observation\ndirectly shows the significant influence of propagated stochasticity on the final variance. It confirms that uncertainty\nintroduced in an initial state is magnified and “carried forward” to the total variance of the final output. The fact that the\n"
    },
    {
      "id": "b-33",
      "type": "body",
      "text": "Finding 2: Findings, citations and answer stochasticity are positively correlated. To examine the relationship\nbetween different types of stochasticity, we plot pairwise scatter plots between variance of findings TV(B),\n                                                                                                      d      variance of\ncitations TV(C), and variance of answers TV(Y) across all temperatures, steps, and modules (Figure 2b). Each point\n          d                                 d\ncorresponds to one experimental condition.\nWe observe strong positive correlations among all variance metrics TV(Y),\n                                                                   d       TV(B),\n                                                                           d      and TV(C),\n                                                                                      d      confirming th"
    },
    {
      "id": "b-34",
      "type": "body",
      "text": "Finding 3: Variance magnitude increases monotonically with temperature. To examine how stochasticity scales\nwith sampling temperature, we compare TV(  d X) e under λ = 0.5 and λ = 1.0 while averaging across the three modules.\nFigure 2c plot the resulting mean final total variance for single-step perturbations at Step 1 and cumulative perturbations\nacross Steps 1–3, respectively.\nAcross both single-step and cumulative settings, higher sampling temperature consistently leads to larger estimated total\nvariance. This monotonic increase indicates that temperature can act as a direct scaling factor for the total variance of\nthe research output. Increasing λ raises the entropy of the component policies (πquery , πsum , πupdate ), thereby increasing\nintrinsic stochasticity at each step and the overall variance."
    },
    {
      "id": "b-35",
      "type": "body",
      "text": "Finding 4: Higher stochasticity does not imply higher accuracy. Although increased stochasticity can encourage\nexploration, our results show that larger variance TV(\n                                                   d X)e does not consistently lead to higher answer accuracy. Table 2\nshows examples where the final variance corresponds to similar or worse accuracy, as stochasticity increases."
    },
    {
      "id": "b-36",
      "type": "body",
      "text": "Table 2: Examples showing that higher stochasticity does not monotonically improve accuracy. We select examples that\nhave each one of λ, step, and module different.\n                                         λ       Step      Module     TV(B)\n                                                                      d           Acc.\n                                        0.5     Step 1      Query       0.76      0.40\n                                        1.0     Step 1      Query       0.80      0.36\n                                        0.5   Combined     Update       0.89      0.41\n                                        1.0   Combined     Update       0.88      0.56\n                                        0.5     Step 1       Sum        0.84      0.40\n                                        0.5     Step 3       Sum        0.52      0.34"
    },
    {
      "id": "b-37",
      "type": "body",
      "text": "Across these examples, we observe that larger TV(B)  d      do not consistently imply higher accuracy, indicating that\nstochasticity alone is not a reliable driver of performance.\n\nFinding 5: Findings are more stochastic than citations. We compare stochasticity at the level of internal findings\n(B) and external citations (C). Table 3 reports averages across λ, step, and module.\n\nTable 3: Average stochasticity of findings vs. citations across modules, steps, and temperatures.\n                                       Metric Findings (B) Citations (C)\n                                         TV(\n                                         d X)e           0.76              0.44\n\n8\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-38",
      "type": "body",
      "text": "Findings (B) exhibit substantially larger total variance than citations (C). This suggests that even though DRAs retrieve\nrelatively consistent evidence sources (indicated by lower citation variance), the process of internalizing that evidence\nthrough information compression and inference policy introduces a significant amount of stochasticity."
    },
    {
      "id": "b-39",
      "type": "body",
      "text": "Finding 6: The inference module has a greater impact on the final stochasticity than the information acquisition\nand compression modules. To compare the effect of different modules causing intrinsic stochasticity, we average the\nstochasticity metrics across time for the three policy modules (Figure 2d). We find that adding stochasticity to πupdate\nyields the highest final output stochasticity across all three metrics. This suggests that mitigating stochasticity during\ninference (belief update) is more impactful for achieving overall system stability than controlling variances for the\ninformation acquisition and compression stages."
    },
    {
      "id": "b-40",
      "type": "body",
      "text": "6     Mitigation Attempt for Stochasticity\nBased on our findings, we provide initial strategies to lower stochasticity in DRA systems while maintaining (or\nincreasing) their accuracy. In order to make our methods generalizable, we switch from a controlled environment to\ncalling backbone LLMs through APIs. A significant challenge in this setting is the non-determinism in API LLM\ninference. Unlike local inference, API inference is non-batch invariant [9], meaning that setting temperature to be 0 is\ninsufficient to eliminate stochasticity.\nSince we cannot reduce stochasticity under this more general setting through lowering temperature as in C.3, we try\nto mitigate stochasticity while preserving accuracy through other algorithmic designs. We call Qwen3-235B-A22B-\nInstruct-2507-tput through Together AI API as backbone and use 20 instances from DeepSearchQA [8] as a more\ncomplex dataset to te"
    },
    {
      "id": "b-41",
      "type": "body",
      "text": "6.1   Method 1: Structured Summarization and Reasoning Output\n\nTo reduce the intrinsic stochasticity of the information compression (πsum ) and inference policy (πupdate ), we impose a\nstructured output constraint for them. By forcing the model to generate outputs within a predefined JSON or Markdown\nschema, we expect to reduce the stylistic variations in the output, there by reducing ∆Sum and ∆Update . An example of\nthe structured output is shown in C.4. As discussed in Finding 6, the stochasticity of the inference module has the\ngreatest influence on the variance of the final output. Therefore, we expect that imposing a structured output constraint\non πupdate will reduce overall stochasticity more than imposing such a constraint on πsum .\n\n6.2   Method 2: Reducing Early-stage Query Stochasticity"
    },
    {
      "id": "b-42",
      "type": "body",
      "text": "We also adopt a consensus-based ensemble for the information acquisition module (πquery ). We issue N independent\n                                                       TN\nsets of queries and retain only the intersection at = i=1 queriesi . This ensures the agent only proceeds with queries\nthat multiple runs have consensus in, effectively reducing early-stage query stochasticity ∆Query . To maintain efficiency,\nwe decay N → 1 as t increases. Since early-stage stochasticity has a greater impact than later-stage stochasticity\n(Finding 1), we expect that this annealing over the number of runs will still effectively reduce variance. Finally, if no\nintersection exists, we use the first proposed set of queries.\n\n6.3   Experimental Result"
    },
    {
      "id": "b-43",
      "type": "body",
      "text": "As shown in Table 4, both mitigation methods reduce the stochasticity of the research output while maintaining (or\nsometimes increasing) the research quality. In addition, imposing structural output constraints on πupdate does reduce\noverall stochasticity more than imposing such a constraint on πsum , reducing the average stochasticity by 5%, and\nimposing structural output constraints for both modules yields more output stability than filtering search queries via\nintersection by an average of 6%. By utilizing all mitigations together, we achieve the lowest stochasticity while having\nthe highest accuracy. For Accuracy, we see a 12% increase w.r.t Baseline, with an average 22% decrease in stochasticity.\nThese results demonstrate that stochasticity can be effectively mitigated through algorithmic design and controlling for\nstochasticity will not degrade the quality of the research output."
    },
    {
      "id": "b-44",
      "type": "body",
      "text": "7     Conclusion\nIn this paper, we provide a systematic analysis of stochasticity in DRAs, introducing principled metrics and a variance-\ndecomposition framework for attributing stochasticity to specific modules and time steps. Our results show that\n\n9\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-45",
      "type": "body",
      "text": "Table 4: Comparison of Stochasticity Mitigation Strategies. The best performance in each category is highlighted\nin bold. Struc. Comb. applies structured summarization and reasoning simultaneously; Comb. integrates all three\nmitigation methods. Avg. TV represents the average value of the three-level stochasticity.\n                                Method          Acc. TV(Y)\n                                                     d     TV(B)\n                                                           d     TV(C)\n                                                                 d     Avg. TV\n                                Baseline        0.24   0.62        0.83   0.62      0.69\n                                Struc. Sum.     0.28   0.58        0.80   0.64      0.67\n                                Struc. Update   0.32   0.52        0.75   0.58      0.62\n                                Struc. Comb"
    },
    {
      "id": "b-46",
      "type": "body",
      "text": "stochasticity injected early in a trajectory propagates strongly and that inference is the dominant source of stochasticity.\nWe also showcase the possibility of reducing stochasticity by proposing mitigation methods based on algorithmic\ndesigns. Overall, this work takes the first step toward building more reproducible deep research agents. Future directions\ninclude designing a broader range of mitigation strategies and developing deeper theoretical analyses of stochasticity in\nDRAs."
    },
    {
      "id": "b-47",
      "type": "body",
      "text": "References\n [1] Salaheddin Alzubi, Creston Brooks, Purva Chiniya, Edoardo Contente, Chiara von Gerlach, Lucas Irwin, Yihan\n     Jiang, Arda Kaz, Windsor Nguyen, Sewoong Oh, et al. Open deep search: Democratizing search with open-source\n     reasoning agents. arXiv preprint arXiv:2503.20201, 2025.\n [2] João Coelho, Jingjie Ning, Jingyuan He, Kangrui Mao, Abhijay Paladugu, Pranav Setlur, Jiahe Jin, Jamie Callan,\n     João Magalhães, Bruno Martins, et al. Deepresearchgym: A free, transparent, and reproducible evaluation sandbox\n     for deep research. arXiv preprint arXiv:2505.19253, 2025.\n [3] Mingxuan Du, Benfeng Xu, Chiwei Zhu, Xiaorui Wang, and Zhendong Mao. Deepresearch bench: A comprehen-\n     sive benchmark for deep research agents. arXiv preprint arXiv:2506.11763, 2025.\n [4] Assaf Elovic. Gpt researcher: An autonomous agent that conducts deep research on any data. https://github."
    },
    {
      "id": "b-48",
      "type": "body",
      "text": "10\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-49",
      "type": "body",
      "text": "[14] Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer,\n     and Hannaneh Hajishirzi. Factscore: Fine-grained atomic evaluation of factual precision in long form text\n     generation. arXiv preprint arXiv:2305.14251, 2023.\n[15] Zairah Mustahsan, Abel Lim, Megna Anand, Saahil Jain, and Bryan McCann. Stochasticity in agentic evaluations:\n     Quantifying inconsistency with intraclass correlation. arXiv preprint arXiv:2512.06710, 2025.\n[16] Lunyiu Nie, Nedim Lipka, Ryan A Rossi, and Swarat Chaudhuri. Flashresearch: Real-time agent orchestration for\n     efficient deep research. arXiv preprint arXiv:2510.05145, 2025.\n[17] OpenAI. Introducing deep research. https://openai.com/index/introducing-deep-research/, 2025.\n[18] Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne Xin Zhao, Lei Fang, and Ji-\n     Rong Wen. R1"
    },
    {
      "id": "b-50",
      "type": "body",
      "text": "11\n\fEvaluating Stochasticity in Deep Research Agents\n\nA     Proofs\nA.1   Proof of Proposition 4.1\n\nProof. By definition, the covariance matrix is the expected outer product of the centered random variable:\n                                  Σ = E (X − µ)(X − µ)⊤ = E[XX⊤ ] − µµ⊤ .\n                                        \u0002                     \u0003\n\nOn the RHS, we have\n                                 E (X1 − X2 )(X⊤    ⊤\n                                  \u0002                    \u0003\n                                               1 − X2 )"
    },
    {
      "id": "b-51",
      "type": "body",
      "text": "= E[X1 X⊤           ⊤           ⊤           ⊤\n                                          1 ] − E[X1 X2 ] − E[X2 X1 ] + E[X2 X2 ].\nSince X1 and X2 are i.i.d., the second moments are equal:\n                                          E[X1 X⊤           ⊤         ⊤\n                                                1 ] = E[X2 X2 ] = E[XX ].\nSince X1 and X2 are independent, we have the expectation of the product is the product of expectations.\n                                          E[X1 X⊤                 ⊤    ⊤\n                                                2 ] = E[X1 ]E[X2 ] = µµ ,"
    },
    {
      "id": "b-52",
      "type": "body",
      "text": "E[X2 X⊤                   ⊤    ⊤\n                                                 1 ] = E[X2 ]E[X1 ] = µµ .\nSubstituting these back into the expression for the RHS, we get\n                                       E (X1 − X2 )(X⊤         ⊤\n                                         \u0002                        \u0003\n                                                         1 − X2 )\n\n= E[XX⊤ ] − µµ⊤ − µµ⊤ + E[XX⊤ ]\n                                         = 2E[XX⊤ ] − 2µµ⊤\n                                         = 2 E[XX⊤ ] − µµ⊤ .\n                                                          \u0001\n\nThis completes the derivation.\n\nA.2   Formal Stochasticity Decomposition"
    },
    {
      "id": "b-53",
      "type": "body",
      "text": "Proposition A.1 (TV Decomposition). Let Xt be the state at time t. The Total Variance at t + 1, denoted TV(Xt+1 ) =\nTr(Var(Xt+1 )), decomposes into a propagated stochasticity term and an intrinsic stochasticity term It :\n                                 TV(Xt+1 ) = TVXt (E[Xt+1 | Xt ]) + EXt [It (Xt )] ,                                     (8)\n                                             |       {z         }   |    {z      }\n                                                  Propagated Stochasticity   Intrinsic Stochasticity"
    },
    {
      "id": "b-54",
      "type": "body",
      "text": "where the intrinsic stochasticity It (Xt ) = Tr(Var(Xt+1 | Xt )) can be further decomposed into three components\ncontrolled by the three policies, respectively:\n                                          It (Xt ) = ∆Query + ∆Sum + ∆Update .                                           (9)\n                                                     | {z } | {z } | {z }\n                                                        πquery        πsum   πupdate"
    },
    {
      "id": "b-55",
      "type": "body",
      "text": "Assuming search results it are deterministic given query at , these components are defined as the traces of their respective\nconditional variances:\n                                 ∆Query = TVat ∼πquery (E[Xt+1 | Xt , at ]) ,\n                                 ∆Sum = Eat [TVht ∼πsum (E[Xt+1 | Xt , at , ht ])] ,\n                                                  \u0002                                      \u0003\n                                 ∆Update = Eat ,ht TVXt+1 ∼πupdate (Xt+1 | Xt , at , ht ) ."
    },
    {
      "id": "b-56",
      "type": "body",
      "text": "The decomposition presented in Proposition A.1 provides a structural lens through which we can audit the sources of\nuncertainty in the agent’s state evolution. By applying the Law of Total Variance, we distinguish between uncertainty\nthat is inherited from previous steps and uncertainty that is generated at the current step.\nThe first term, Propagated Stochasticity, quantifies the ‘momentum’ of prior stochasticity. Mathematically, it represents\nthe variance of the conditional expectation; conceptually, it captures how much of the variance in Xt+1 is simply a\nresult of the agent starting from a noisy distribution Xt .\nOn the other hand, the Intrinsic Stochasticity term, EXt [It (Xt )], represents the stochasticity introduced during the\ncurrent time step t + 1. It measures the variance that remains even if the previous state Xt were known with absolute\ncertainty. By labeling this as a intr"
    },
    {
      "id": "b-57",
      "type": "body",
      "text": "12\n\fEvaluating Stochasticity in Deep Research Agents\n\n• ∆Query measures the variance of the expected output caused by the agent’s choice of information acquisition actions\n   at .\n • ∆Sum reflects the variance introduced by the compression and synthesis of external search results into the summary\n   ht .\n • ∆Update captures the variance in the belief state update (inference), i.e., the stochasticity in integrating the synthesized\n   information to infer the next state Xt+1 ."
    },
    {
      "id": "b-58",
      "type": "body",
      "text": "A.2.1    Proof of Proposition A.1\nProof. We apply the Law of Total Variance for random vectors, Var(X) = Var(E[X|Z]) + E[Var(X|Z)]. Since the\ntrace operator is linear, Tr(Var(X)) = Tr(Var(E[X|Z])) + E[Tr(Var(X|Z))]. We apply this recursively across the\ncausal chain: Xt → at → ht → Xt+1 .\nIsolation of History. Conditioning on the previous state Xt , we separate the variance propagated from the history\ndistribution from the fresh variance introduced at step t:\n                                        TV(Xt+1 ) = Tr (VarXt (E[Xt+1 | Xt ]))\n                                                    + EXt [TV(Xt+1 | Xt )]\nThe second term is the expected intrinsic injection. We now decompose the inner term TV(Xt+1 | Xt ).\nIsolation of Query Divergence (∆Query ). Conditioning on the action at ∼ πquery , we apply the Law of Total Variance:\n                                    TV(Xt+1 | Xt ) = Tr (Varat ("
    },
    {
      "id": "b-59",
      "type": "body",
      "text": "B     Prompts\nB.1     Claim Decomposition\n\nListing 1: Claim Decomposition\n\n# # Task Description\nExtract all factual claims from the provided report . Each claim should be a\n     factual statement that\ncan be verified . Claims may or may not have supporting citations .\n\n# # Input\nA Research Question and a complete report containing factual claims , some of which\n      may have\ncitation markers and corresponding URLs ( either inline or in a reference section ) .\n\n# # Output Requirements\n\n13\n\fEvaluating Stochasticity in Deep Research Agents"
    },
    {
      "id": "b-60",
      "type": "body",
      "text": "- Extract each distinct factual claim throughout the entire report\n- For each claim , output a JSON object with :\n  - The exact claim text as a string\n  - The original text from the report containing this claim ( context )\n  - The corresponding citation URL as source ( if a citation marker directly\n    follows the claim )\n- If a claim has a citation marker directly following it , return the supporting\n    URL as source\n- If a claim does not have a citation marker directly following it , return an\n    empty string for source\n- Ensure all string values are properly escaped for valid JSON format ( e . g . ,\n    Replace internal quotation\n  marks ( \" ) with escaped quotation marks (\\\\ \" ) ) in the claim and context\n- Return a JSON array containing all claim objects"
    },
    {
      "id": "b-61",
      "type": "body",
      "text": "# # Format Specification\n[\n   {\n      \" claim \" : \" The exact statement representing a factual claim \" ,\n      \" context \" : \" The original sentence or passage from the report containing this\n     claim \" ,\n      \" source \" : \" https :// example . com / source1 \"\n   },\n   {\n      \" claim \" : \" Another factual statement without direct citation \" ,\n      \" context \" : \" The original sentence or passage from the report containing this\n     claim \" ,\n      \" source \" : \" \"\n   }\n]"
    },
    {
      "id": "b-62",
      "type": "body",
      "text": "## Guidelines for Claim Identification\n1. A claim should be a complete , standalone factual statement\n2. Maintain the original wording where possible , but remove unnecessary context\n3. Extract all factual claims regardless of whether they have citation support\n4. Only map citation markers ( numbers , author names , etc .) to their corresponding\n    URLs in\n   the references section when the marker directly follows the claim statement\n5. Exclude opinions , speculations , or methodological descriptions\n6. Extract the context passage containing each claim for verification purposes\n7. If multiple claims are associated with the same citation , extract them as\n    separate entries"
    },
    {
      "id": "b-63",
      "type": "body",
      "text": "# # Citation URL Mapping\n- If URLs appear directly after claims , use those URLs directly\n- Citation markers ( e . g . , a number or [ number ]) must directly follow the claim to\n     be considered\n   as supporting that claim\n- If claims use citation markers that reference a bibliography or reference\n     section , locate the corresponding\n   URLs in that section\n- If a claim has no directly following citation marker , use an empty string for\n     source\n\nB.2   Atomic Finding Decomposition"
    },
    {
      "id": "b-64",
      "type": "body",
      "text": "Listing 2: Atomic Fact Decomposition\nYou are given a factual statement ( a claim ) from a technical report .\nBreak the claim down into independent , minimal atomic facts that can each be\nverified in isolation . Keep each atomic fact short , declarative , and free of\nconjunctions when possible . Avoid duplicating the same content in multiple ways\nunless it clarifies distinct atomic facts ( e . g . , subject + membership vs subject +\n     role ) .\n\n14\n\fEvaluating Stochasticity in Deep Research Agents\n\nFormat :\n- Return a JSON array of strings . Each string is one atomic fact .\n- Do not include any extra commentary or Markdown . Only return the JSON array .\n\nExamples :\nInput : \" He was an American composer , conductor , and musical director .\"\nOutput : [\n  \" He was an American .\" ,\n  \" He was a composer .\" ,\n  \" He was a conductor .\" ,\n  \" He was a musical director .\"\n]"
    },
    {
      "id": "b-65",
      "type": "body",
      "text": "Input : \" She currently stars in the romantic comedy series , Love and Destiny , which\n      premiered in 2019.\"\nOutput : [\n  \" She currently stars in Love and Destiny .\" ,\n  \" Love and Destiny is a romantic comedy series .\" ,\n  \" Love and Destiny premiered in 2019.\"\n]"
    },
    {
      "id": "b-66",
      "type": "body",
      "text": "Input : \" During his professional career , McCoy played for the Broncos , the San\n     Diego Chargers , the Minnesota Vikings , and the Jacksonville Jaguars .\"\nOutput : [\n  \" McCoy played for the Broncos .\" ,\n  \" McCoy played for the Broncos during his professional career .\" ,\n  \" McCoy played for the San Diego Chargers .\" ,\n  \" McCoy played for the San Diego Chargers during his professional career .\" ,\n  \" McCoy played for the Minnesota Vikings .\" ,\n  \" McCoy played for the Minnesota Vikings during his professional career .\" ,\n  \" McCoy played for the Jacksonville Jaguars .\" ,\n  \" McCoy played for the Jacksonville Jaguars during his professional career .\"\n]\n\nInput : \" The EU approved the AI Act in 2024 and introduced new compliance\n     requirements .\"\nOutput : [\n  \" The EU approved the AI Act in 2024.\" ,\n  \" The AI Act introduced new compliance requirements .\"\n]"
    },
    {
      "id": "b-67",
      "type": "body",
      "text": "Input : \" The Amazon River is the largest by discharge and flows into the Atlantic\n     Ocean .\"\nOutput : [\n  \" The Amazon River is the largest river by discharge .\" ,\n  \" The Amazon River flows into the Atlantic Ocean .\"\n]\n\nNow decompose the following claim into atomic facts and return only a JSON array\n    of strings :\n\nB.3   Answer Extraction\n\nListing 3: Atomic Fact Decomposition\n## Task Description\nExtract the answer to the research question from the provided report .\n\n## Input\nA Research Question and a complete report containing the answer .\n\n## Output Requirements\nExtract the direct answer to the research question\n\n15\n\fEvaluating Stochasticity in Deep Research Agents\n\nProvide supporting evidence / context from the report\nReturn a JSON object with the answer and supporting context"
    },
    {
      "id": "b-68",
      "type": "body",
      "text": "## Format Specification\n{\n  \" question \": \" The research question \" ,\n  \" answer \": \" The direct answer extracted from the report \" ,\n  \" su pp or ting_context \": \" Key passages from the report that support this answer \"\n}\n\n##   Guidelines\n1.   Focus on directly answering the research question\n2.   Be concise but comprehensive\n3.   Include relevant evidence and context\n4.   Maintain factual accuracy\n\n16\n\fEvaluating Stochasticity in Deep Research Agents\n\nC     Additional Details\n\nC.1     Instantiation 2: Open Deep Research"
    },
    {
      "id": "b-69",
      "type": "body",
      "text": "The Outer Loop (Supervisor). The outer loop operates on the global research state. It operates over a sequence of\ndiscrete steps t = 1, 2, ..., T . We define the components as follows:\n                                 outer\n • Information Acquisition (πquery     ): The outer loop thinking strategy is parameterized by a backbone LLM. It generates\n   an action at ∈ S outer ∪ T outer , where S outer is the space of research topics and T outer is the termination signal.\n                       outer\n • Search Engine (βengine    ): If at ∈ S outer , the agent executes the inner loop to generate synthesized reports it ∼\n   InnerLoop(· | at ).\n                                   outer\n • Information Compression (πsum         ): The outer loop does not conduct this step. Therefore, ht = ⊮(it ), where ⊮ is the\n   identity function.\n                outer\n • Inference (πupdate ): The outer belief is "
    },
    {
      "id": "b-70",
      "type": "body",
      "text": "C.2     Details about Evaluation Metrics\n\nC.2.1    Probabilistic Interpretation\nFor the one-hot encoding vector Y, let yi denote the one-hot vector representation of the outcome y (i) from run i.\nSince yi is a standard basis vector, it has unit norm (∥yi ∥2 = 1). Consequently, the squared Euclidean distance between\ntwo runs simplifies to a discrete metric:\n\n0 if y (i) ≡ y (j)\n                                                             \u001a\n                                                        2\n                                             ∥yi − yj ∥ =                                                            (12)\n                                                               2 if y (i) ̸≡ y (j)"
    },
    {
      "id": "b-71",
      "type": "body",
      "text": "Substituting this into Eq. (6), the estimator reduces to the proportion of discordant pairs across all possible comparisons:\n                                                        1     X\n                                         TV(Y)\n                                         c     =                I(y (i) ̸≡ y (j) ).                                      (13)\n                                                     n(n − 1)\n                                                                  i̸=j\n\nThis value represents the empirical probability that two independently sampled runs will produce different answers.\nFor binary vectors B, C, the squared distance between two normalized vectors relates directly to their Cosine similarity:"
    },
    {
      "id": "b-72",
      "type": "body",
      "text": "∥e    ej ∥2 = 2 − 2(e\n                                               xi − x             xi · x\n                                                                       ej ).                                             (14)\n\nSubstituting the cosine identity ∥e    ej ∥2 = 2 − 2(e\n                                  xi − x             xi · x\n                                                          ej ) into Eq. (6), the estimator simplifies to the average\ncomplement of the cosine similarity:\n\nc =1−          1     X\n                                            TV                     xi · x\n                                                                  (e    ej ).                                            (15)\n                                                        n(n − 1)\n                                                                     i̸=j"
    },
    {
      "id": "b-73",
      "type": "body",
      "text": "We use findings as an illustrative example. Let Si denote the set of finding indices discovered in run i. Consider two\nruns i and j. Assuming the volume of findings is consistent across runs such that |Si | = |Sj | = k, the dot product of\n\n17\n\fEvaluating Stochasticity in Deep Research Agents\n\nthe normalized vectors approximates the conditional probability of recurrence:\n                                                   |Si ∩ Sj |\n                                        ei · x\n                                        x    ej = p\n                                                     |Si ||Sj |\n                                                  |Si ∩ Sj |\n                                                =\n                                                       k\n                                                = P (finding ∈ Sj | finding ∈ Si ).                                  (16)"
    },
    {
      "id": "b-74",
      "type": "body",
      "text": "Taking the expectation over all pairs, we arrive at the following probabilistic interpretation:\n                                       c = 1 − P (finding ∈ Sj | finding ∈ Si ).\n                                     E[TV]                                                                           (17)"
    },
    {
      "id": "b-75",
      "type": "body",
      "text": "C.2.2   Incorporating Semantic Geometry\nIn our primary analysis, we treat answers and findings as categorical distributions — disagreeing on ‘cat’ vs. ‘dog’\nincurs the same penalty as ‘cat’ vs. ‘car’. If we consider the semantic geometry of answers (i.e., answer ‘cat’ is closer\nto ‘dog’ than to ‘car’ in some embedding space) and findings, our TV framework naturally extends to this setting by\nredefining the realization vectors using embedding distances.\nFor a semantic space equipped with a similarity metric s(u, v) ∈ [0, 1], we can generalize our vector construction.\n • Answers: Instead of a one-hot vector ek , the realization yi becomes the dense embedding vector vy(i) . The\n   Euclidean distance ∥yi − yj ∥2 then directly captures semantic divergence (e.g., small for ‘cat’ vs. ‘dog’, large for\n   ‘cat’ vs. ‘car’).\n • Findings/Citations: If the global set of findings is {f1 , . . . , fK }"
    },
    {
      "id": "b-76",
      "type": "body",
      "text": "C.2.3   Sensitivity to Relative Scale\nA potential concern with using L2 normalization is that it discards the absolute magnitude of the vectors (i.e., the total\nnumber of findings). However, this property is desirable for measuring stability: it ensures that our metric focuses on\nthe relative consistency of the information retrieved, rather than the raw volume.\nTo illustrate this, consider how the metric penalizes a “single omission’ error — where one run misses exactly one\nfinding discovered by another run. Intuitively, missing 1 finding out of 10 is a more severe failure of consistency\ncompared to missing 1 finding out of 100. Our normalized TV  c captures this distinction. As an example, we compare\ntwo scenarios where Run 1 generates a set of findings S1 and Run 2 generates S2 , with an intersection size of |S1 ∩ S2 |.\n • Case A: The agent discovers 100 findings in Run 1, but misses o"
    },
    {
      "id": "b-77",
      "type": "body",
      "text": "c A = 1 − √ 99\n                                      TV                  = 1 − 0.995 = 0.005\n                                                 100 × 99\n • Case B: The agent discovers 10 findings in Run 1, but misses one in Run 2 (|S1 | = 10, |S2 | = 9, |S1 ∩ S2 | = 9).\n\ncB = 1 − √ 9\n                                        TV               = 1 − 0.949 = 0.051\n                                                  10 × 9\nAlthough the absolute disagreement is identical (1 finding difference) in both cases, the estimator assigns a penalty to\nCase B that is an order of magnitude larger (≈ 10×). This confirms that TVc correctly scales.\n\n18\n\fEvaluating Stochasticity in Deep Research Agents\n\nC.3   Mitigation in API Setting through Temperature Tuning"
    },
    {
      "id": "b-78",
      "type": "body",
      "text": "Table 5: Stochasticity and Accuracy Metrics across Sampling Temperatures (λ) under API Setting.\n                                     Metric      T = 0 λ = 0.5 λ = 1.0\n                                       TV(Y)\n                                       d             0.700        0.670    0.620\n                                       TV(B)\n                                       d             0.828        0.836    0.834\n                                       TV(C)\n                                       d             0.621        0.608    0.612\n                                       Accuracy       0.28        0.24      0.24\n\nC.4   Example for Structured Output"
    },
    {
      "id": "b-79",
      "type": "body",
      "text": "Listing 4: Structured Reasoning Output\n< reasoning >{\\ n \\\" established_facts \\\": [] ,\\ n \\\" open_questions \\\": [\\ n                                     \\\" Which\n     countries were in the top 10 with the lowest GPI scores in both 2022 and 2023\n     according to Vision of Humanity ?\\\" ,\\ n                                  \\\" Of those countries , which had a gun\n     homicide rate below 0.20 per 100 ,000 population in both 2022 and 2023 according\n       to World Population Review ?\\\" ,\\ n                                \\\" Are the GPI scores and gun homicide rate\n       data available and comparable for the same set of countries across both years\n     ?\\\"\\ n ] ,\\ n \\\" n ex t_ sea rc h_ dir ec ti on s \\\": [\\ n                         \\\" Search for the Global Peace\n     Index ( GPI ) 2022 and 2023 reports from Vision of Humanity to identify the top\n     10 most peaceful countries ( lowest sc"
    },
    {
      "id": "b-80",
      "type": "body",
      "text": "19"
    }
  ]
}